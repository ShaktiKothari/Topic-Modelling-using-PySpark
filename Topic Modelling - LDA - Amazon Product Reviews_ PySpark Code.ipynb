{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7f907d833310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.HiveContext at 0x7f907d8555d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlCtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data =sqlCtx.read.format(\"csv\").option(\"header\", True) \\\n",
    ".option(\"inferSchema\",True) \\\n",
    ".option(\"delimiter\", \"\\t\") \\\n",
    ".load(\"file:/home/cloudera/amazon_reviews_us_Watches_v1_00.tsv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>3653882</td>\n",
       "      <td>R3O9SGZBVQBV76</td>\n",
       "      <td>B00FALQ1ZC</td>\n",
       "      <td>937001370</td>\n",
       "      <td>Invicta Women's 15150 \"Angel\" 18k Yellow Gold ...</td>\n",
       "      <td>Watches</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Absolutely love this watch! Get compliments al...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>14661224</td>\n",
       "      <td>RKH8BNC3L5DLF</td>\n",
       "      <td>B00D3RGO20</td>\n",
       "      <td>484010722</td>\n",
       "      <td>Kenneth Cole New York Women's KC4944 Automatic...</td>\n",
       "      <td>Watches</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>I love thiswatch it keeps time wonderfully</td>\n",
       "      <td>I love this watch it keeps time wonderfully.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US      3653882  R3O9SGZBVQBV76  B00FALQ1ZC       937001370   \n",
       "1          US     14661224   RKH8BNC3L5DLF  B00D3RGO20       484010722   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  Invicta Women's 15150 \"Angel\" 18k Yellow Gold ...          Watches   \n",
       "1  Kenneth Cole New York Women's KC4944 Automatic...          Watches   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              0            0    N                 Y   \n",
       "1            5              0            0    N                 Y   \n",
       "\n",
       "                              review_headline  \\\n",
       "0                                  Five Stars   \n",
       "1  I love thiswatch it keeps time wonderfully   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0  Absolutely love this watch! Get compliments al...  2015-08-31  \n",
       "1       I love this watch it keeps time wonderfully.  2015-08-31  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|star_rating|\n",
      "+-----------+\n",
      "|          1|\n",
      "|          2|\n",
      "|          3|\n",
      "|          4|\n",
      "|          5|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"star_rating\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.registerTempTable(\"watches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = sqlCtx.sql(\"select star_rating, review_body from watches where star_rating == 1 group by star_rating, review_body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import re # needed to remove special character\n",
    "from pyspark import Row\n",
    "\n",
    "import json\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer\n",
    "from pyspark.mllib.clustering import LDA\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, LongType\n",
    "from pyspark.sql.functions import *\n",
    "from nltk.stem.porter import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1rdd = data1.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern1 = re.compile('\\W+|\\W+$|[^\\w\\s]+|_')\n",
    "pattern2 = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
    "\n",
    "#pattern1 = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
    "\n",
    "rdd = data1rdd \\\n",
    "    .mapValues(lambda x: pattern1.sub(' ', x)) \\\n",
    "    .mapValues(lambda x: pattern2.sub(' ', x))\n",
    "\n",
    "df = rdd.toDF(schema=['file', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row_with_index = Row(*[\"id\"] + df.columns)\n",
    "\n",
    "def make_row(columns):\n",
    "    def _make_row(row, uid):\n",
    "        row_dict = row.asDict()\n",
    "        return row_with_index(*[uid] + [row_dict.get(c) for c in columns])\n",
    "\n",
    "    return _make_row\n",
    "\n",
    "f = make_row(df.columns)\n",
    "\n",
    "indexed = (df.rdd\n",
    "           .zipWithUniqueId()\n",
    "           .map(lambda x: f(*x))\n",
    "           .toDF(StructType([StructField(\"id\", LongType(), False)] + df.schema.fields)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "tokenized = tokenizer.transform(indexed)\n",
    "print 'done'\n",
    "\n",
    "# remove stop words\n",
    "stopwordList = ['','get','got','also','really','me','my','myself','we',\n",
    " 'our','ours','ourselves','you','your','yours','yourself','yourselves','he','him',\n",
    " 'his','himself','she','her','hers','herself','it','its','itself','they',\n",
    " 'them','their', 'theirs','themselves','what','which','who','whom','this',\n",
    " 'that','these','those','am','is','are','was','were','be','been',\n",
    " 'being','have','has','had','having','do','does','did','doing','a','an','the',\n",
    " 'and','but','if','or','because','as','until','while','of','at','by','for',\n",
    " 'with','about','against','between','into','through','during','before','after',\n",
    " 'above','below','to','from','up','down','in','out','on','off','over','under','again',\n",
    " 'further','then','once','here','there','when','where','why','how','all',\n",
    " 'any','both','each','few','more','most','other','some','such','no','nor','not','only',\n",
    " 'own','same','so','than','too','very','s','t','can','will''just','don',\n",
    " 'should','now','d','ll','m','o','re','ve','y','ain', 'aren', 'couldn','didn',\n",
    " 'doesn','hadn','hasn','haven','isn','ma','mightn','mustn','needn',\n",
    " 'shan','shouldn','wasn','weren','won','wouldn']\n",
    "\n",
    "\n",
    "# Removing Stop words\n",
    "remover=StopWordsRemover(inputCol=\"tokens\", outputCol=\"words\" ,stopWords=stopwordList)\n",
    "cleaned = remover.transform(tokenized)\n",
    "print 'done'\n",
    "\n",
    "#stem words\n",
    "# Instantiate stemmer object\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Create stemmer python function\n",
    "def stem(in_vec):\n",
    "    out_vec = []\n",
    "    for t in in_vec:\n",
    "        t_stem = stemmer.stem(t)\n",
    "        if len(t_stem) > 2:\n",
    "            out_vec.append(t_stem)       \n",
    "    return out_vec\n",
    "\n",
    "# Create user defined function for stemming with return type Array<String>\n",
    "stemmer_udf = udf(lambda x: stem(x), ArrayType(StringType()))\n",
    "\n",
    "# Create new df with vectors containing the stemmed tokens \n",
    "# Create new df with vectors containing the stemmed tokens \n",
    "vector_stemmed_df = (\n",
    "    cleaned\n",
    "        .withColumn(\"vector_stemmed\", stemmer_udf(\"words\"))\n",
    "  )\n",
    "\n",
    "\n",
    "# vectorize\n",
    "cv = CountVectorizer(inputCol=\"vector_stemmed\", outputCol=\"vectors\")\n",
    "print 'done'\n",
    "count_vectorizer_model = cv.fit(vector_stemmed_df)\n",
    "print 'done'\n",
    "result = count_vectorizer_model.transform(vector_stemmed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = result.select(F.col('id').cast(\"long\"), 'vectors').rdd \\\n",
    "    .map(lambda x: [x[0], x[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "lda_model = LDA.train(rdd=corpus, k=5, seed=12, maxIterations=10)\n",
    "# extracting topics\n",
    "topics = lda_model.describeTopics(maxTermsPerTopic=10)\n",
    "# extraction vocabulary\n",
    "vocabulary = count_vectorizer_model.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 : \n",
      "(u'watch', '->', 0.060781673589666)\n",
      "(u'time', '->', 0.014287839356970554)\n",
      "(u'work', '->', 0.013246304321076435)\n",
      "(u'look', '->', 0.010901606695168048)\n",
      "(u'one', '->', 0.01079050843574341)\n",
      "(u'return', '->', 0.008826846018517201)\n",
      "(u'band', '->', 0.008339117703619855)\n",
      "(u'would', '->', 0.00829779803929313)\n",
      "(u'like', '->', 0.007865306446118782)\n",
      "(u'day', '->', 0.007723457313712524)\n",
      "topic 1 : \n",
      "(u'watch', '->', 0.06314514555240586)\n",
      "(u'time', '->', 0.014639522777564515)\n",
      "(u'work', '->', 0.012716100846548133)\n",
      "(u'look', '->', 0.010855964680423874)\n",
      "(u'one', '->', 0.010710404326144512)\n",
      "(u'return', '->', 0.008608957512747754)\n",
      "(u'would', '->', 0.008523473508861984)\n",
      "(u'band', '->', 0.008180929130094142)\n",
      "(u'like', '->', 0.007644169254708581)\n",
      "(u'day', '->', 0.0074096512300357385)\n",
      "topic 2 : \n",
      "(u'watch', '->', 0.06227913119291515)\n",
      "(u'time', '->', 0.015073561580536146)\n",
      "(u'work', '->', 0.01297282494378452)\n",
      "(u'look', '->', 0.011227993586512261)\n",
      "(u'one', '->', 0.010511664106660365)\n",
      "(u'return', '->', 0.009207032281607803)\n",
      "(u'would', '->', 0.008625827159920572)\n",
      "(u'band', '->', 0.008004330370443033)\n",
      "(u'like', '->', 0.007573974447472506)\n",
      "(u'day', '->', 0.007414354662847926)\n",
      "topic 3 : \n",
      "(u'watch', '->', 0.061383129847013496)\n",
      "(u'time', '->', 0.014308113571174487)\n",
      "(u'work', '->', 0.012859594566761163)\n",
      "(u'one', '->', 0.010978699570971005)\n",
      "(u'look', '->', 0.01095691398612332)\n",
      "(u'return', '->', 0.008964658001205654)\n",
      "(u'would', '->', 0.008183231892154903)\n",
      "(u'band', '->', 0.00791315604631886)\n",
      "(u'day', '->', 0.007598797589132065)\n",
      "(u'like', '->', 0.007458539121260385)\n",
      "topic 4 : \n",
      "(u'watch', '->', 0.06157462948123369)\n",
      "(u'time', '->', 0.014594299691272714)\n",
      "(u'work', '->', 0.013199279582198338)\n",
      "(u'look', '->', 0.011204553274121239)\n",
      "(u'one', '->', 0.010883522877783157)\n",
      "(u'band', '->', 0.008625725626213207)\n",
      "(u'return', '->', 0.008581976202802797)\n",
      "(u'would', '->', 0.008238715469803117)\n",
      "(u'like', '->', 0.0076550632225172)\n",
      "(u'day', '->', 0.007485460315463906)\n"
     ]
    }
   ],
   "source": [
    "for topic in range(len(topics)):\n",
    "    print(\"topic {} : \".format(topic))\n",
    "    words = topics[topic][0]\n",
    "    scores = topics[topic][1]\n",
    "    for word in range(len(words)):\n",
    "        print(vocabulary[words[word]], \"->\", scores[word])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
